import streamlit as st
import google.generativeai as genai
import json, re, os, io, base64, tempfile
from google.cloud import vision
from PIL import Image
import pdfplumber

# ===========================
# 1) ููุงุชูุญ ูุฑุจุท ุงูุฎุฏูุงุช
# ===========================
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY", None)
VISION_KEY_B64 = st.secrets.get("GOOGLE_VISION_KEY_B64", None)

if GEMINI_KEY:
    genai.configure(api_key=GEMINI_KEY)

if VISION_KEY_B64:
    key_json = base64.b64decode(VISION_KEY_B64).decode("utf-8")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp:
        tmp.write(key_json.encode("utf-8"))
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp.name


# ===========================
# 2) OCR ุดุงูู (ุตูุฑ + PDF)
# ===========================
def _vision_client():
    return vision.ImageAnnotatorClient()

def _ocr_image_bytes(client: vision.ImageAnnotatorClient, img_bytes: bytes) -> str:
    image = vision.Image(content=img_bytes)
    resp = client.document_text_detection(image=image)
    if resp.error.message:
        raise RuntimeError(resp.error.message)
    if resp.full_text_annotation and resp.full_text_annotation.text:
        return resp.full_text_annotation.text
    if resp.text_annotations:
        return resp.text_annotations[0].description
    return ""

def extract_text_any(uploaded_file, dpi: int = 200) -> str:
    """
    ูุฏุนู PDF + ุตูุฑ (PNG/JPG). ููู PDF ููุญููู ูู ุตูุญุฉ ุฅูู ุตูุฑุฉ ุซู ูุทุจูู OCR.
    """
    name = (uploaded_file.name or "").lower()
    uploaded_file.seek(0)
    data = uploaded_file.read()

    client = _vision_client()

    if name.endswith(".pdf"):
        pages_text = []
        with pdfplumber.open(io.BytesIO(data)) as pdf:
            for page in pdf.pages:
                pil = page.to_image(resolution=dpi).original.convert("RGB")
                buf = io.BytesIO()
                pil.save(buf, format="PNG")
                pages_text.append(_ocr_image_bytes(client, buf.getvalue()))
        return ("\n\n--- ุตูุญุฉ ุฌุฏูุฏุฉ ---\n\n".join(t.strip() for t in pages_text)).strip()
    else:
        pil = Image.open(io.BytesIO(data)).convert("RGB")
        buf = io.BytesIO()
        pil.save(buf, format="PNG")
        return _ocr_image_bytes(client, buf.getvalue())


# ===========================
# 3) Prompt ุงููุณูู (ูุน ุชูุฑูุจ ุงูุฃููุงุณ)
# ===========================
AGREEMENT_PROMPT_TEMPLATE = r"""
ุฃูุช ูุณุงุนุฏ ูุชุญููู ุงุชูุงููุงุช "ุงููุคุณุณุฉ ุงูุงุณุชููุงููุฉ ุงูุนุณูุฑูุฉ".
ุฃุนุฏ ุงูุฑุฏ **ุจุงูุถุจุท** ุจูุฐู ุงููุณููุ ูุจุฏูู ุฃู ูุต ุฎุงุฑุฌูุงุ ูุจุฏูู ุชุนูููุงุช ุฃู ุดุฑูุญุงุช:

<<<TEAM_A>>>
[ุงูุชุจ ุงุณู ุงููุฑูู ุงูุฃูู ููุท]
<<<END_TEAM_A>>>

<<<TEAM_B>>>
[ุงูุชุจ ุงุณู ุงููุฑูู ุงูุซุงูู ููุท]
<<<END_TEAM_B>>>

<<<DATE_START>>>
[ุชุงุฑูุฎ ุงูุจุฏุก ุจุตูุบุฉ YYYY-MM-DD ุฃู ุงุชุฑูู ูุงุฑุบุงู]
<<<END_DATE_START>>>

<<<DATE_END>>>
[ุชุงุฑูุฎ ุงูุงูุชูุงุก ุจุตูุบุฉ YYYY-MM-DD ุฃู ุงุชุฑูู ูุงุฑุบุงู]
<<<END_DATE_END>>>

<<<SUMMARY>>>
[3โ5 ููุงุท ูุตูุฑุฉ ุฌุฏุงู ุชูุฎูุต ุงูุงุชูุงููุฉุ ููุทุฉ ููู ุณุทุฑ ุชุจุฏุฃ ุจู "- "]
<<<END_SUMMARY>>>

# ุงููุตูููุฉ ุงูุชุงููุฉ ููุท ุจุตูุบุฉ JSON ุตุญูุญุฉ. ูุง ุชุถู ุฃู ูุต ุฎุงุฑุฌ ุงูุฃููุงุณ.
# ุฃููููุฉ ูุตูู ูุงุณุชุฎุฑุงุฌ ุงูููุงุฏ ุจุดูู ุตุญูุญ.
# ุงูุดุฑูุท:
# - "ุงุณู_ุงููุงุฏุฉ": ูุต (ุฏุงุฆูุงู String)
# - ุจุงูู ุงูุญููู ุฃุฑูุงู ุนุดุฑูุฉ ุจุงูุฏููุงุฑ ุจุนุฏ ุฏูุฌ ุงูุฏููุงุฑ+ุงูููุณ (ุฅู ูุฌุฏุชุง ูููุตูุชูู ุจุงููุต).
# - "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ" ุนุฏุฏ ุตุญูุญ (ุงูุชุจ ุฑููุงู ููุท).
# - "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช" ููููุฉ ุนุดุฑูุฉ (ูุซูุงู 0.16 ูููุณ 16%).
# - ูุง ุชุนูููุงุชุ ูุง ููุงุตู ุฒุงุฆุฏุฉ ูุจู ] ุฃู }}.
# - ุฅู ูู ุชูุฌุฏ ููุงุฏุ ุฃุนุฏ ูุตูููุฉ ูุงุฑุบุฉ [].
<<<ITEMS_JSON_ARRAY>>>
[
  {{
    "ุงุณู_ุงููุงุฏุฉ": "ูุซุงู",
    "ุณุนุฑ_ุงูุดุฑุงุก_ูุจู_ุงูุถุฑูุจุฉ": 0.0,
    "ุณุนุฑ_ุงูุดุฑุงุก_ูุน_ุงูุถุฑูุจุฉ": 0.0,
    "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ": 0,
    "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ": 0.0,
    "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช": 0.0
  }}
]
<<<END_ITEMS_JSON_ARRAY>>>

<<<WARRANTIES>>>
[ุญููู ููุฑุฉ ุงูููุงูุงุช ุฅูู ููุงุท ูุตูุฑุฉ ุฌุฏุงูุ ููุทุฉ ููู ุณุทุฑ ุชุจุฏุฃ ุจู "- "]
<<<END_WARRANTIES>>>

<<<SPECIAL_TERMS>>>
[ุญููู ุงูุดุฑูุท ุงูุฎุงุตุฉ ุฅูู ููุงุท ูุตูุฑุฉ ุฌุฏุงูุ ููุทุฉ ููู ุณุทุฑ ุชุจุฏุฃ ุจู "- "]
<<<END_SPECIAL_TERMS>>>

<<<GENERAL_TERMS>>>
[ุญููู ุงูุดุฑูุท ุงูุนุงูุฉ ุฅูู ููุงุท ูุตูุฑุฉ ุฌุฏุงูุ ููุทุฉ ููู ุณุทุฑ ุชุจุฏุฃ ุจู "- "]
<<<END_GENERAL_TERMS>>>

ุชุนูููุงุช ูููุฉ:
- ุฑููุฒ ุนูู ุงุณุชุฎุฑุงุฌ (ุงูุชูุงุฑูุฎ + ุงูููุงุฏ) ุจุฏูุฉ ุนุงููุฉ.
- ูุญููุฏ ุงูุฃุณุนุงุฑ ุจุงูุฏููุงุฑ ููุท (ุงุฌูุน ุงูุฏููุงุฑ + ุงูููุณ/1000 ุฅู ุธูุฑุช ูููุตูุฉ).
- ุงูุชุฒู ุจุงูุจููุฉ ุฃุนูุงู ุญุฑููุงู.
ุงููุต:
----------------
{doc_text}
"""



# ===========================
# 4) ุชุญููู ุงููุณูู + ุชูุธูู JSON ุงูููุงุฏ
# ===========================
def _between(s: str, start_tag: str, end_tag: str) -> str:
    pat = re.compile(re.escape(start_tag) + r"(.*?)" + re.escape(end_tag), re.S)
    m = pat.search(s)
    return (m.group(1).strip() if m else "")

def parse_tagged_response(raw: str) -> dict:
    import json, re
    # ุฅุฒุงูุฉ ูุญุงุฑู ุงูุงุชุฌุงู/BOM/Zero-width
    raw = re.sub(r"[\u200E\u200F\u202A-\u202E\u2066-\u2069\uFEFF\u200B\u200C\u200D]", "", raw).strip()

    def g(a, b):
        pat = re.compile(re.escape(a) + r"(.*?)" + re.escape(b), re.S)
        m = pat.search(raw)
        return (m.group(1).strip() if m else "")

    def to_points(text: str) -> list:
        """ุญููู ุณุทูุฑ ุชุจุฏุฃ ุจู '- ' ุฅูู ููุงุท ูุตูุฑุฉ ูุธููุฉ."""
        if not text:
            return []
        lines = [re.sub(r"^\s*-\s*", "", ln).strip() for ln in text.splitlines() if ln.strip()]
        # ุงุญุชูุธ ููุท ุจุงูุณุทุฑ ุงูุฐู ูุงู ูุจุฏุฃ ุจู "- " ุฃู ูุตูุฑ ุฌุฏุงู
        out = []
        for ln in lines:
            if ln.startswith("- "):
                ln = ln[2:].strip()
            out.append(ln)
        # ููุชุฑุฉ ุงููุฑุงุบุงุช ูุชุญุฏูุฏ ุญุฏ ุฃูุตู ููุทูู
        out = [x for x in out if x]
        return out[:20]  # ุณูู 20 ููุทุฉ

    items_json = g("<<<ITEMS_JSON_ARRAY>>>", "<<<END_ITEMS_JSON_ARRAY>>>").strip()
    items = []
    if items_json:
        # ุฅุฒุงูุฉ code fences ุฅู ููุฌุฏุช
        items_json = re.sub(r"^```(?:json)?\s*|\s*```$", "", items_json, flags=re.IGNORECASE | re.MULTILINE).strip()
        # ุชุทุจูุน ุนูุงูุงุช ุงูุงูุชุจุงุณ ูุงูููุงุตู ุงูุนุฑุจูุฉ
        items_json = (items_json
                      .replace("โ", '"').replace("โ", '"').replace("โ", "'").replace("โ", "'")
                      .replace("ุ", ",").replace("ูซ", "."))
        # ุฅุฒุงูุฉ ุงูููุงุตู ุงูุฒุงุฆุฏุฉ ูุจู ุงูุฃููุงุณ
        items_json = re.sub(r",\s*([}\]])", r"\1", items_json)
        # ุงูุชุจุงุณ ุงูููุงุชูุญ ุบูุฑ ุงูููุชุจุณุฉ
        items_json = re.sub(r'([{,]\s*)([A-Za-z0-9_ุก-ู]+)\s*:', r'\1"\2":', items_json)
        # ุฃุญูุงูุงู ุงุณู_ุงููุงุฏุฉ ููุนุงุฏ ุฑูููุง โ ุงูุชุจุณู ูุณูุณูุฉ
        items_json = re.sub(r'("ุงุณู_ุงููุงุฏุฉ"\s*:\s*)(-?\d+(?:\.\d+)?)', r'\1"\2"', items_json)

        try:
            parsed = json.loads(items_json)
        except Exception:
            items_json2 = re.sub(r"\s+\n\s+", "\n", items_json)
            try:
                parsed = json.loads(items_json2)
            except Exception:
                parsed = []

        if isinstance(parsed, dict):
            items = [parsed]
        elif isinstance(parsed, list):
            items = [x for x in parsed if isinstance(x, dict)]
        else:
            items = []
    else:
        items = []

    summary_txt   = g("<<<SUMMARY>>>",        "<<<END_SUMMARY>>>")
    warranties    = g("<<<WARRANTIES>>>",     "<<<END_WARRANTIES>>>")
    special_terms = g("<<<SPECIAL_TERMS>>>",  "<<<END_SPECIAL_TERMS>>>")
    general_terms = g("<<<GENERAL_TERMS>>>",  "<<<END_GENERAL_TERMS>>>")

    return {
        "ุงููุฑูู_ุงูุฃูู":   g("<<<TEAM_A>>>", "<<<END_TEAM_A>>>"),
        "ุงููุฑูู_ุงูุซุงูู":  g("<<<TEAM_B>>>", "<<<END_TEAM_B>>>"),
        "ุชุงุฑูุฎ_ุงูุจุฏุก":    g("<<<DATE_START>>>", "<<<END_DATE_START>>>"),
        "ุชุงุฑูุฎ_ุงูุงูุชูุงุก": g("<<<DATE_END>>>",   "<<<END_DATE_END>>>"),
        "ููุฎุต_ุงูุงุชูุงููุฉ": summary_txt,             # ุงููุต ุงูุฃุตูู (ุงุญุชูุงุท)
        "ููุฎุต_ุงูุงุชูุงููุฉ_ููุงุท": to_points(summary_txt),
        "ุงูููุงุฏ": items,
        "ููุฑุฉ_ุงูููุงูุงุช": warranties,               # ุงููุต ุงูุฃุตูู (ุงุญุชูุงุท)
        "ููุฑุฉ_ุงูููุงูุงุช_ููุงุท": to_points(warranties),
        "ุงูุดุฑูุท_ุงูุฎุงุตุฉ": special_terms,            # ุงููุต ุงูุฃุตูู (ุงุญุชูุงุท)
        "ุงูุดุฑูุท_ุงูุฎุงุตุฉ_ููุงุท": to_points(special_terms),
        "ุงูุดุฑูุท_ุงูุนุงูุฉ": general_terms,            # ุงููุต ุงูุฃุตูู (ุงุญุชูุงุท)
        "ุงูุดุฑูุท_ุงูุนุงูุฉ_ููุงุท": to_points(general_terms),
    }



# ===========================
# 4.1) ุฃุฏูุงุช ุงูุชุฌุฒุฆุฉ ูุงูุฏูุฌ + ูุงุฆูุฉ ุงูููุฏููุงุช ุงูุงุญุชูุงุทูุฉ
# ===========================
def chunk_text(text: str, max_chars: int = 10000) -> list:
    """
    ููุต ุงููุต ููุทุน ุฃูุตุฑ ุญุชู ูุง ูุฑูุถู ุงูููุฏูู ุจุณุจุจ ุงูุทูู.
    ูุฑุงุนู ุงููุต ุนูุฏ ููุงูุฉ ุณุทุฑ ุฅู ุฃููู.
    """
    text = text or ""
    if len(text) <= max_chars:
        return [text]
    chunks, start = [], 0
    while start < len(text):
        end = min(len(text), start + max_chars)
        # ุญุงูู ุงููุต ุนูุฏ ุฃูุฑุจ ุณุทุฑุ ุจุดุฑุท ุฃูุง ูุฑุฌุน ูุซูุฑุงู
        nl = text.rfind("\n", start, end)
        if nl == -1 or nl <= start + int(max_chars * 0.5):
            nl = end
        chunk = text[start:nl].strip()
        if chunk:
            chunks.append(chunk)
        start = nl
    return chunks

def merge_results(parts: list) -> dict:
    """
    ูุฏูุฌ ูุชุงุฆุฌ ูุชุนุฏุฏุฉ ูู parse_tagged_response ูู ูุชูุฌุฉ ูุงุญุฏุฉ.
    ูุฃุฎุฐ ุฃูู ูููุฉ ุบูุฑ ูุงุฑุบุฉ ููุญููู ุงููุฑุฏูุฉ ููุฌูุน ุงูุฌุฏุงูู ูุงููุตูุต.
    """
    merged = {
        "ุงููุฑูู_ุงูุฃูู": None,
        "ุงููุฑูู_ุงูุซุงูู": None,
        "ุชุงุฑูุฎ_ุงูุจุฏุก": None,
        "ุชุงุฑูุฎ_ุงูุงูุชูุงุก": None,
        "ููุฎุต_ุงูุงุชูุงููุฉ": "",
        "ุงูููุงุฏ": [],
        "ููุฑุฉ_ุงูููุงูุงุช": "",
        "ุงูุดุฑูุท_ุงูุฎุงุตุฉ": "",
        "ุงูุดุฑูุท_ุงูุนุงูุฉ": ""
    }

    def first_nonempty(cur, new):
        return cur if (cur and str(cur).strip()) else (new if (new and str(new).strip()) else cur)

    for p in parts or []:
        merged["ุงููุฑูู_ุงูุฃูู"]    = first_nonempty(merged["ุงููุฑูู_ุงูุฃูู"],    p.get("ุงููุฑูู_ุงูุฃูู"))
        merged["ุงููุฑูู_ุงูุซุงูู"]   = first_nonempty(merged["ุงููุฑูู_ุงูุซุงูู"],   p.get("ุงููุฑูู_ุงูุซุงูู"))
        merged["ุชุงุฑูุฎ_ุงูุจุฏุก"]     = first_nonempty(merged["ุชุงุฑูุฎ_ุงูุจุฏุก"],     p.get("ุชุงุฑูุฎ_ุงูุจุฏุก"))
        merged["ุชุงุฑูุฎ_ุงูุงูุชูุงุก"]  = first_nonempty(merged["ุชุงุฑูุฎ_ุงูุงูุชูุงุก"],  p.get("ุชุงุฑูุฎ_ุงูุงูุชูุงุก"))

        if p.get("ููุฎุต_ุงูุงุชูุงููุฉ"):
            if merged["ููุฎุต_ุงูุงุชูุงููุฉ"]:
                merged["ููุฎุต_ุงูุงุชูุงููุฉ"] += "\nโข " + p["ููุฎุต_ุงูุงุชูุงููุฉ"].strip()
            else:
                merged["ููุฎุต_ุงูุงุชูุงููุฉ"] = "โข " + p["ููุฎุต_ุงูุงุชูุงููุฉ"].strip()

        if p.get("ุงูููุงุฏ"):
            merged["ุงูููุงุฏ"].extend([x for x in p["ุงูููุงุฏ"] if isinstance(x, dict)])

        for k in ["ููุฑุฉ_ุงูููุงูุงุช","ุงูุดุฑูุท_ุงูุฎุงุตุฉ","ุงูุดุฑูุท_ุงูุนุงูุฉ"]:
            if p.get(k):
                if merged[k]:
                    merged[k] += "\n" + p[k].strip()
                else:
                    merged[k] = p[k].strip()

    return merged

def _model_fallbacks(selected: str) -> list:
    """
    ูุจูู ูุงุฆูุฉ ููุฏููุงุช ูุฌุฑุจูุง ุจุงูุชุณูุณู.
    """
    seen, out = set(), []
    def add(m):
        if m and m not in seen:
            seen.add(m); out.append(m)

    add(selected)
    if "2.5" in selected:
        add(selected.replace("2.5", "1.5"))

    add("models/gemini-1.5-pro")
    add("models/gemini-1.5-flash")
    add("models/gemini-1.5-pro-001")
    add("models/gemini-1.5-flash-001")
    return out


# ===========================
# 4.2) ุชูุณูู ุฌุฏูู ุงูููุงุฏ (ุชูุธูู ุฃุฑูุงู + ุฃุนูุฏุฉ ูุดุชูุฉ + ุนุฑุถ)
# ===========================
def _arabic_digits_to_western(s: str) -> str:
    if not isinstance(s, str):
        s = str(s)
    trans = str.maketrans("ููกูขูฃูคูฅูฆูงูจูฉ", "0123456789")
    return s.translate(trans)

def _to_float(val):
    """ูุญุงูู ุชุญููู ุฃู ุชูุซูู ุฑููู (ุนุฑุจู/ุฅูุฌููุฒู) ุฅูู float ุจุฃูุงู."""
    if val is None:
        return None
    if isinstance(val, (int, float)):
        return float(val)
    s = str(val).strip()
    if not s:
        return None
    # ุทุจูุน ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ + ุงูููุงุตู ุงูุนุฑุจูุฉ
    s = _arabic_digits_to_western(s)
    s = s.replace("ุ", ",").replace("ูซ", ".")
    # ุฃุฒู ุงููููุงุช ุงูุดุงุฆุนุฉ
    s = re.sub(r"(ุฏููุงุฑ|JD|ุฏ\.|ููุณ|ุถุฑูุจุฉ|%)", "", s, flags=re.I).strip()
    # ุฃุฒู ููุงุตู ุงูุขูุงู ูุงููุณุงูุงุช
    s = s.replace(",", "").replace(" ", "")
    # ุงูุชูุท ุฃูู ุฑูู ุนุดุฑู ุตุงูุญ (ูุฏุนู ุงูุณุงูุจ)
    m = re.search(r"-?\d+(?:\.\d+)?", s)
    if not m:
        return None
    try:
        return float(m.group(0))
    except Exception:
        return None

def normalize_items_table(items: list):
    """ูุนูุฏ DataFrame ููุธูู + ุฃุฑูุงู ููุญุฏุฉ + ุฃุนูุฏุฉ ูุดุชูุฉ ููุฌุงููุน."""
    import pandas as pd
    cols = [
        "ุงุณู_ุงููุงุฏุฉ",
        "ุณุนุฑ_ุงูุดุฑุงุก_ูุจู_ุงูุถุฑูุจุฉ",
        "ุณุนุฑ_ุงูุดุฑุงุก_ูุน_ุงูุถุฑูุจุฉ",
        "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ",
        "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ",
        "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช",
    ]
    # ุถูุงู ูุฌูุฏ ุงูุฃุนูุฏุฉ
    norm_rows = []
    for it in (items or []):
        row = {k: it.get(k) for k in cols}
        norm_rows.append(row)
    df = pd.DataFrame(norm_rows, columns=cols)

    # ุชุญููู ุงูุฃุฑูุงู
    for c in ["ุณุนุฑ_ุงูุดุฑุงุก_ูุจู_ุงูุถุฑูุจุฉ", "ุณุนุฑ_ุงูุดุฑุงุก_ูุน_ุงูุถุฑูุจุฉ", "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ",
              "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ", "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช"]:
        df[c] = df[c].apply(_to_float)

    # ูุณุจุฉ ุงูุถุฑูุจุฉ: ุฅู ูุงูุช ุจูู 1..100 ุงุนุชุจุฑูุง % ููุณููุง ุนูู 100
    df["ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช"] = df["ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช"].apply(
        lambda x: (x/100.0) if (x is not None and 1.0 <= x <= 100.0) else x
    )

    # ุฃุนูุฏุฉ ูุดุชูุฉ
    df["ูููุฉ_ูุจู_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"] = (
        (df["ุณุนุฑ_ุงูุดุฑุงุก_ูุจู_ุงูุถุฑูุจุฉ"].fillna(0.0)) * (df["ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ"].fillna(0.0))
    )
    df["ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"] = (
        (df["ุณุนุฑ_ุงูุดุฑุงุก_ูุน_ุงูุถุฑูุจุฉ"].fillna(0.0)) * (df["ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ"].fillna(0.0))
    )

    # ุฅู ูุงูุช "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ" ูุงุฑุบุฉุ ูููุฃูุง ุจุงูุญุณุงุจ ุงููุชุงุญ
    df["ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ"] = df["ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ"].fillna(
        df["ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"].where(df["ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"] > 0, df["ูููุฉ_ูุจู_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"])
    )

    # ุชุฑุชูุจ ุฃุนูุฏุฉ ุงูุนุฑุถ
    display_cols = [
        "ุงุณู_ุงููุงุฏุฉ",
        "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ",
        "ุณุนุฑ_ุงูุดุฑุงุก_ูุจู_ุงูุถุฑูุจุฉ",
        "ุณุนุฑ_ุงูุดุฑุงุก_ูุน_ุงูุถุฑูุจุฉ",
        "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช",
        "ูููุฉ_ูุจู_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)",
        "ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)",
        "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ",
    ]
    # ูุฌุงููุน
    totals = {
        "ุฅุฌูุงูู_ุงููููุฉ": float(df["ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ"].fillna(0).sum()),
        "ุฅุฌูุงูู_ูููุฉ_ูุจู_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)": float(df["ูููุฉ_ูุจู_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"].fillna(0).sum()),
        "ุฅุฌูุงูู_ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)": float(df["ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)"].fillna(0).sum()),
        "ุฅุฌูุงูู_ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ": float(df["ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ"].fillna(0).sum()),
    }
    return df[display_cols], totals

def render_items_table(items: list, title: str = "๐ฆ ุงูููุงุฏ ุถูู ุงูุงุชูุงููุฉ"):
    """ูุนุฑุถ ุงูุฌุฏูู + ููุฎุต + ุฃุฒุฑุงุฑ ุชูุฒูู."""
    import pandas as pd
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown(f'<div class="section-title">{title}</div>', unsafe_allow_html=True)

    df, totals = normalize_items_table(items)

    if df.empty:
        st.info("ูุง ุชูุฌุฏ ููุงุฏ ูุณุชุฎุฑุฌุฉ.")
        st.markdown('</div>', unsafe_allow_html=True)
        return

    # ุนุฑุถ ุงูุฌุฏูู
    st.dataframe(df, use_container_width=True, height=420)

    # ููุฎุต ุณุฑูุน
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ุฅุฌูุงูู ุงููููุฉ", f"{totals['ุฅุฌูุงูู_ุงููููุฉ']:.0f}")
    c2.metric("ุฅุฌูุงูู ูุจู ุงูุถุฑูุจุฉ", f"{totals['ุฅุฌูุงูู_ูููุฉ_ูุจู_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)']:.3f}")
    c3.metric("ุฅุฌูุงูู ูุน ุงูุถุฑูุจุฉ", f"{totals['ุฅุฌูุงูู_ูููุฉ_ูุน_ุงูุถุฑูุจุฉ_(ุญุณุงุจ)']:.3f}")
    c4.metric("ุฅุฌูุงูู ุงููููุฉ ุงููุฏุฎูุฉ", f"{totals['ุฅุฌูุงูู_ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ']:.3f}")

    # ุชูุฒูู CSV/Excel
    csv_bytes = df.to_csv(index=False).encode("utf-8")
    st.download_button("โฌ๏ธ ุชูุฒูู CSV", data=csv_bytes, file_name="items.csv", mime="text/csv")

    try:
        import io
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
            df.to_excel(writer, index=False, sheet_name="items")
        st.download_button("โฌ๏ธ ุชูุฒูู Excel", data=buf.getvalue(),
                           file_name="items.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    except Exception:
        pass

    st.markdown('</div>', unsafe_allow_html=True)


# ===========================
# 5) ุชุญููู ุจุงูู Gemini (ูุญุงููุฉ ูุงููุฉ ุซู ุชุฌุฒุฆุฉ)
# ===========================
def analyze_agreement_with_gemini(text: str, selected_model: str, debug: bool = False) -> dict:
    """
    ุฃููุงู ูุญุงูู ุชุญููู ูุงูู ุงููุต. ุฅุฐุง ูุดู (ุฑุฏ ูุงุถู/ูุฑููุถ/ุฎุทุฃ)ุ
    ููุชูู ููุฎุทุฉ (ุจ): ุชูุณูู ุงููุต ููุทุน ูุชุดุบูู ุงูุชุญููู ุนูู ูู ูุทุนุฉุ ุซู ุฏูุฌ ุงููุชูุฌุฉ.
    """
    prompt_full = AGREEMENT_PROMPT_TEMPLATE.format(doc_text=text)

    def run_once(model_name: str, prompt: str) -> str:
        model = genai.GenerativeModel(model_name=model_name)
        resp = model.generate_content(
            prompt,
            generation_config={"temperature": 0.15, "max_output_tokens": 8192}
        )
        raw = getattr(resp, "text", "") or ""
        if not raw and getattr(resp, "candidates", None):
            parts = [p.text for c in resp.candidates for p in getattr(c.content, "parts", []) if getattr(p, "text", "")]
            raw = "\n".join(parts)
        return raw

    # 1) ูุญุงููุฉ ูุงููุฉ ูุน fallback ุนูู ุงูููุฏููุงุช
    for m in _model_fallbacks(selected_model):
        try:
            raw = run_once(m, prompt_full)
            if debug:
                st.caption(f"๐ Raw (full) from {m}:")
                st.code((raw or "")[:1200] + ("..." if raw and len(raw) > 1200 else ""))
            parsed = parse_tagged_response(raw)
            # ูู ุจุนุถ ุงูุญููู ุชููุฃุช ุฃู ูู ููุงุฏุ ุงุนุชุจุฑูุง ูุงุฌุญุฉ
            if any([parsed.get("ุงููุฑูู_ุงูุฃูู"), parsed.get("ุงููุฑูู_ุงูุซุงูู"), parsed.get("ุงูููุงุฏ")]):
                return parsed
        except Exception as e:
            if debug:
                st.warning(f"โ๏ธ ูุดู ูุญุงููุฉ ูุงููุฉ ุนูู {m}: {type(e).__name__}: {e}")

    # 2) ุฎุทุฉ (ุจ): ุชุฌุฒุฆุฉ ุงููุต
    chunks = chunk_text(text, max_chars=10000)
    parts = []
    for idx, ch in enumerate(chunks, 1):
        prompt_chunk = AGREEMENT_PROMPT_TEMPLATE.format(doc_text=ch)
        ok = False
        for m in _model_fallbacks(selected_model):
            try:
                raw = run_once(m, prompt_chunk)
                if debug:
                    st.caption(f"๐ Raw (chunk {idx}/{len(chunks)}) from {m}:")
                    st.code((raw or "")[:800] + ("..." if raw and len(raw) > 800 else ""))
                parsed = parse_tagged_response(raw)
                parts.append(parsed)
                ok = True
                break
            except Exception as e:
                if debug:
                    st.warning(f"โ๏ธ ูุดู chunk {idx} ุนูู {m}: {type(e).__name__}: {e}")
                continue
        if not ok and debug:
            st.error(f"โ ูู ููุฌุญ ูู chunk {idx}")

    if not parts:
        raise RuntimeError("ูุดู ุงูุชุญููู ุนุจุฑ ุฌููุน ุงูููุฏููุงุช (ูุงูู + ูุฌุฒุฃ).")

    # ุฏูุฌ ุงููุชุงุฆุฌ ุงูุฌุฒุฆูุฉ
    merged = merge_results(parts)
    return merged


# ===========================
# 6) ูุงุฌูุฉ Streamlit
# ===========================
st.set_page_config(page_title="ุชุญููู ุงุชูุงููุงุช ุงููุคุณุณุฉ ุงูุงุณุชููุงููุฉ ุงูุนุณูุฑูุฉ", layout="wide")

# ููุณุฉ CSS ุจุณูุทุฉ
st.markdown("""
<style>
.section-title{font-weight:700;font-size:1.1rem;margin:8px 0 12px}
.card{background:#ffffff;border:1px solid #eee;border-radius:12px;padding:12px;margin-bottom:14px}
</style>
""", unsafe_allow_html=True)

st.title("๐ ูุธุงู ุชุญููู ุงุชูุงููุงุช ุงููุคุณุณุฉ ุงูุงุณุชููุงููุฉ ุงูุนุณูุฑูุฉ")
st.markdown("ุจุงุณุชุฎุฏุงู **Google Vision OCR + Gemini AI**")

uploaded = st.file_uploader("๐ค ุงุฑูุน ุตูุฑุฉ ุฃู ููู PDF", type=["png", "jpg", "jpeg", "pdf"])

if uploaded and st.button("๐ ุงุณุชุฎุฑุงุฌ ุงููุต"):
    try:
        with st.spinner("ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ุงููุต ุนุจุฑ Google Vision..."):
            text = extract_text_any(uploaded)
        st.session_state["ocr_text"] = text
        st.success("โ ุชู ุงุณุชุฎุฑุงุฌ ุงููุต!")
    except Exception as e:
        st.error(f"โ ูุดู ุงุณุชุฎุฑุงุฌ ุงููุต: {e}")

# ุนุฑุถ ุงููุต
st.text_area("๐ ุงููุต ุงููุณุชุฎุฑุฌ:", st.session_state.get("ocr_text", ""), height=300)

# ุฅุนุฏุงุฏ Gemini
if GEMINI_KEY:
    st.success("โ ููุชุงุญ Gemini ุตุงูุญ.")
    try:
        models_list = genai.list_models()
        models = [m.name for m in models_list if "generateContent" in m.supported_generation_methods]
    except Exception:
        # fallback ููุฃุณูุงุก ุงูุดุงุฆุนุฉ ูู ูุดู list_models
        models = [
            "models/gemini-1.5-pro",
            "models/gemini-1.5-flash",
            "models/gemini-1.5-pro-001",
            "models/gemini-1.5-flash-001",
        ]
    selected_model = st.selectbox("ุงุฎุชุฑ ุงูููุฏูู:", models, index=0)
else:
    st.error("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ููุชุงุญ Gemini")
    selected_model = None

debug = st.toggle("๐ง ุฅุธูุงุฑ ูุฎุฑุฌุงุช ุงูุชุดุฎูุต (Raw)")

if "ocr_text" in st.session_state and selected_model and st.button("ุชุญููู ุงูุงุชูุงููุฉ"):
    try:
        result = analyze_agreement_with_gemini(st.session_state["ocr_text"], selected_model, debug)
        st.success("โ ุชู ุงูุชุญููู ุจูุฌุงุญ")

        # ุนุฑุถ ุงูุฃูุณุงู ุจุดูู ุฃููู
        with st.container():
            c1, c2 = st.columns(2)
            with c1:
                st.markdown('<div class="card"><div class="section-title">๐ฅ ุงููุฑูู ุงูุฃูู</div>', unsafe_allow_html=True)
                st.write(result.get("ุงููุฑูู_ุงูุฃูู") or "โ")
                st.markdown('</div>', unsafe_allow_html=True)

            with c2:
                st.markdown('<div class="card"><div class="section-title">๐ฅ ุงููุฑูู ุงูุซุงูู</div>', unsafe_allow_html=True)
                st.write(result.get("ุงููุฑูู_ุงูุซุงูู") or "โ")
                st.markdown('</div>', unsafe_allow_html=True)

        with st.container():
            c3, c4 = st.columns(2)
            with c3:
                st.markdown('<div class="card"><div class="section-title">๐ ุชุงุฑูุฎ ุงูุจุฏุก</div>', unsafe_allow_html=True)
                st.write(result.get("ุชุงุฑูุฎ_ุงูุจุฏุก") or "โ")
                st.markdown('</div>', unsafe_allow_html=True)
            with c4:
                st.markdown('<div class="card"><div class="section-title">๐ ุชุงุฑูุฎ ุงูุงูุชูุงุก</div>', unsafe_allow_html=True)
                st.write(result.get("ุชุงุฑูุฎ_ุงูุงูุชูุงุก") or "โ")
                st.markdown('</div>', unsafe_allow_html=True)

        st.markdown('<div class="card"><div class="section-title">๐ ููุฎุต ุงูุงุชูุงููุฉ</div>', unsafe_allow_html=True)
        st.write(result.get("ููุฎุต_ุงูุงุชูุงููุฉ") or "โ")
        st.markdown('</div>', unsafe_allow_html=True)

        # ุฌุฏูู ุงูููุงุฏ
        render_items_table(result.get("ุงูููุงุฏ", []) or [])

        # ุจุงูู ุงูุฃูุณุงู ุงููุตูุฉ
        with st.container():
            st.markdown('<div class="card"><div class="section-title">๐ก๏ธ ููุฑุฉ ุงูููุงูุงุช</div>', unsafe_allow_html=True)
            st.write(result.get("ููุฑุฉ_ุงูููุงูุงุช") or "โ")
            st.markdown('</div>', unsafe_allow_html=True)

        with st.container():
            st.markdown('<div class="card"><div class="section-title">โ๏ธ ุงูุดุฑูุท ุงูุฎุงุตุฉ</div>', unsafe_allow_html=True)
            st.write(result.get("ุงูุดุฑูุท_ุงูุฎุงุตุฉ") or "โ")
            st.markdown('</div>', unsafe_allow_html=True)

        with st.container():
            st.markdown('<div class="card"><div class="section-title">๐ ุงูุดุฑูุท ุงูุนุงูุฉ</div>', unsafe_allow_html=True)
            st.write(result.get("ุงูุดุฑูุท_ุงูุนุงูุฉ") or "โ")
            st.markdown('</div>', unsafe_allow_html=True)

        # ุนุฑุถ JSON ุงูุฎุงู (ููุชูุฒูู/ุงููุฑุงุฌุนุฉ)
        with st.expander("๐ JSON ุงููุงูู ูููุชูุฌุฉ"):
            st.json(result)

    except Exception as e:
        st.error(f"โ ูุดู ุงูุชุญููู: {e}")
