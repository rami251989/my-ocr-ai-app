import streamlit as st
import google.generativeai as genai
import json, re, os, io, base64, tempfile
from google.cloud import vision
from PIL import Image
import pdfplumber

# ===========================
# 1๏ธโฃ ุฅุนุฏุงุฏ ุงูููุงุชูุญ
# ===========================
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY", None)
VISION_KEY_B64 = st.secrets.get("GOOGLE_VISION_KEY_B64", None)

if GEMINI_KEY:
    genai.configure(api_key=GEMINI_KEY)

if VISION_KEY_B64:
    key_json = base64.b64decode(VISION_KEY_B64).decode("utf-8")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp:
        tmp.write(key_json.encode("utf-8"))
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp.name


# ===========================
# 2๏ธโฃ OCR ุดุงูู (ุตูุฑ + PDF)
# ===========================
def _vision_client():
    return vision.ImageAnnotatorClient()

def _ocr_image_bytes(client: vision.ImageAnnotatorClient, img_bytes: bytes) -> str:
    image = vision.Image(content=img_bytes)
    resp = client.document_text_detection(image=image)
    if resp.error.message:
        raise RuntimeError(resp.error.message)
    if resp.full_text_annotation and resp.full_text_annotation.text:
        return resp.full_text_annotation.text
    if resp.text_annotations:
        return resp.text_annotations[0].description
    return ""

def extract_text_any(uploaded_file, dpi: int = 200) -> str:
    """
    ูุฏุนู PDF + ุตูุฑ (PNG/JPG). ููู PDF ููุญููู ูู ุตูุญุฉ ุฅูู ุตูุฑุฉ ุซู ูุทุจูู OCR.
    """
    name = (uploaded_file.name or "").lower()
    uploaded_file.seek(0)
    data = uploaded_file.read()

    client = _vision_client()

    if name.endswith(".pdf"):
        pages_text = []
        with pdfplumber.open(io.BytesIO(data)) as pdf:
            for page in pdf.pages:
                pil = page.to_image(resolution=dpi).original.convert("RGB")
                buf = io.BytesIO()
                pil.save(buf, format="PNG")
                pages_text.append(_ocr_image_bytes(client, buf.getvalue()))
        return ("\n\n--- ุตูุญุฉ ุฌุฏูุฏุฉ ---\n\n".join(t.strip() for t in pages_text)).strip()
    else:
        pil = Image.open(io.BytesIO(data)).convert("RGB")
        buf = io.BytesIO()
        pil.save(buf, format="PNG")
        return _ocr_image_bytes(client, buf.getvalue())

# ===========================
# 3๏ธโฃ Prompt ุงููุณูู
# ===========================
AGREEMENT_PROMPT_TEMPLATE = r"""
ุฃูุช ูุณุงุนุฏ ูุชุญููู ุงุชูุงููุงุช "ุงููุคุณุณุฉ ุงูุงุณุชููุงููุฉ ุงูุนุณูุฑูุฉ".
ุฃุนุฏ ุงูุฑุฏ **ุจุงูุถุจุท** ุจูุฐู ุงููุณููุ ูุจุฏูู ุฃู ูุต ุฎุงุฑุฌูุงุ ูุจุฏูู ุชุนูููุงุช ุฃู ุดุฑูุญุงุช:

<<<TEAM_A>>>
[ุงูุชุจ ุงุณู ุงููุฑูู ุงูุฃูู ููุท]
<<<END_TEAM_A>>>

<<<TEAM_B>>>
[ุงูุชุจ ุงุณู ุงููุฑูู ุงูุซุงูู ููุท]
<<<END_TEAM_B>>>

<<<DATE_START>>>
[ุชุงุฑูุฎ ุงูุจุฏุก ุจุตูุบุฉ YYYY-MM-DD ุฃู ุงุชุฑูู ูุงุฑุบุงู]
<<<END_DATE_START>>>

<<<DATE_END>>>
[ุชุงุฑูุฎ ุงูุงูุชูุงุก ุจุตูุบุฉ YYYY-MM-DD ุฃู ุงุชุฑูู ูุงุฑุบุงู]
<<<END_DATE_END>>>

<<<SUMMARY>>>
[ููุฎุต ููุฌุฒ ุฌุฏุงู ููุงุชูุงููุฉ]
<<<END_SUMMARY>>>

# ุงููุตูููุฉ ุงูุชุงููุฉ ููุท ุจุตูุบุฉ JSON ุตุญูุญุฉ. ูุง ุชุถู ุฃู ูุต ุฎุงุฑุฌ ุงูุฃููุงุณ.
# ุงูุดุฑูุท:
# - "ุงุณู_ุงููุงุฏุฉ": ูุต (ุฏุงุฆูุงู String)
# - ุจุงูู ุงูุญููู ุฃุฑูุงู ุนุดุฑูุฉ ุจุงูุฏููุงุฑ ุจุนุฏ ุฏูุฌ ุงูุฏููุงุฑ+ุงูููุณ (ุฅู ูุฌุฏุชุง ูููุตูุชูู ุจุงููุต).
# - "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ" ุนุฏุฏ ุตุญูุญ (ุงูุชุจ ุฑููุงู ููุท).
# - "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช" ููููุฉ ุนุดุฑูุฉ (ูุซูุงู 0.16 ูููุณ 16%).
# - ูุง ุชุนูููุงุชุ ูุง ููุงุตู ุฒุงุฆุฏุฉ ูุจู ] ุฃู }}.
# - ุฅู ูู ุชูุฌุฏ ููุงุฏุ ุฃุนุฏ ูุตูููุฉ ูุงุฑุบุฉ [].
<<<ITEMS_JSON_ARRAY>>>
[
  {{
    "ุงุณู_ุงููุงุฏุฉ": "ูุซุงู",
    "ุณุนุฑ_ุงูุดุฑุงุก_ูุจู_ุงูุถุฑูุจุฉ": 0.0,
    "ุณุนุฑ_ุงูุดุฑุงุก_ูุน_ุงูุถุฑูุจุฉ": 0.0,
    "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุญุจุฉ": 0,
    "ุงููููุฉ_ุงููุดุชุฑุงุฉ_ุจุงูุฏููุงุฑ": 0.0,
    "ูุณุจุฉ_ุถุฑูุจุฉ_ุงููุจูุนุงุช": 0.0
  }}
]
<<<END_ITEMS_JSON_ARRAY>>>

<<<WARRANTIES>>>
[ูุต ููุฑุฉ ุงูููุงูุงุช ุฅู ูุฌุฏุช]
<<<END_WARRANTIES>>>

<<<SPECIAL_TERMS>>>
[ุงูุดุฑูุท ุงูุฎุงุตุฉ ุฅู ูุฌุฏุช]
<<<END_SPECIAL_TERMS>>>

<<<GENERAL_TERMS>>>
[ุงูุดุฑูุท ุงูุนุงูุฉ ุฅู ูุฌุฏุช]
<<<END_GENERAL_TERMS>>>

ุชุนูููุงุช ูููุฉ:
- ูุญููุฏ ุงูุฃุณุนุงุฑ ุจุงูุฏููุงุฑ ููุท (ุงุฌูุน ุงูุฏููุงุฑ + ุงูููุณ/1000 ุฅู ุธูุฑุช ูููุตูุฉ).
- ุงูุชุฒู ุจุงูุจููุฉ ุฃุนูุงู ุญุฑููุงู.
ุงููุต:
----------------
{doc_text}
"""

# ===========================
# 4๏ธโฃ ุชุญููู ุงููุณูู
# ===========================
def _between(s: str, start_tag: str, end_tag: str) -> str:
    pat = re.compile(re.escape(start_tag) + r"(.*?)" + re.escape(end_tag), re.S)
    m = pat.search(s)
    return (m.group(1).strip() if m else "")

def parse_tagged_response(raw: str) -> dict:
   def chunk_text(text: str, max_chars: int = 12000) -> list:
    """
    ููุต ุงููุต ููุทุน ูุตูุฑุฉ ุญุชู ูุง ูุฑูุถู ุงูููุฏูู ุจุณุจุจ ุงูุทูู.
    ูุฑุงุนู ุงููุตู ุนูู ุญุฏูุฏ ุฃุณุทุฑ ุฅู ุฃููู.
    """
    text = text or ""
    if len(text) <= max_chars:
        return [text]
    chunks, start = [], 0
    while start < len(text):
        end = min(len(text), start + max_chars)
        # ุญุงูู ุงููุต ุนูุฏ ุฃูุฑุจ ุณุทุฑ
        nl = text.rfind("\n", start, end)
        if nl == -1 or nl <= start + int(max_chars*0.5):
            nl = end
        chunks.append(text[start:nl].strip())
        start = nl
    return [c for c in chunks if c]


def merge_results(parts: list) -> dict:
    """
    ูุฏูุฌ ูุงุฆูุฉ ูุชุงุฆุฌ parse_tagged_response.
    """
    merged = {
        "ุงููุฑูู_ุงูุฃูู": None,
        "ุงููุฑูู_ุงูุซุงูู": None,
        "ุชุงุฑูุฎ_ุงูุจุฏุก": None,
        "ุชุงุฑูุฎ_ุงูุงูุชูุงุก": None,
        "ููุฎุต_ุงูุงุชูุงููุฉ": "",
        "ุงูููุงุฏ": [],
        "ููุฑุฉ_ุงูููุงูุงุช": "",
        "ุงูุดุฑูุท_ุงูุฎุงุตุฉ": "",
        "ุงูุดุฑูุท_ุงูุนุงูุฉ": ""
    }
    def first_nonempty(cur, new):
        return cur if (cur and str(cur).strip()) else (new if (new and str(new).strip()) else cur)

    for p in parts:
        merged["ุงููุฑูู_ุงูุฃูู"]    = first_nonempty(merged["ุงููุฑูู_ุงูุฃูู"],    p.get("ุงููุฑูู_ุงูุฃูู"))
        merged["ุงููุฑูู_ุงูุซุงูู"]   = first_nonempty(merged["ุงููุฑูู_ุงูุซุงูู"],   p.get("ุงููุฑูู_ุงูุซุงูู"))
        merged["ุชุงุฑูุฎ_ุงูุจุฏุก"]     = first_nonempty(merged["ุชุงุฑูุฎ_ุงูุจุฏุก"],     p.get("ุชุงุฑูุฎ_ุงูุจุฏุก"))
        merged["ุชุงุฑูุฎ_ุงูุงูุชูุงุก"]  = first_nonempty(merged["ุชุงุฑูุฎ_ุงูุงูุชูุงุก"],  p.get("ุชุงุฑูุฎ_ุงูุงูุชูุงุก"))

        if p.get("ููุฎุต_ุงูุงุชูุงููุฉ"):
            if merged["ููุฎุต_ุงูุงุชูุงููุฉ"]:
                merged["ููุฎุต_ุงูุงุชูุงููุฉ"] += "\nโข " + p["ููุฎุต_ุงูุงุชูุงููุฉ"].strip()
            else:
                merged["ููุฎุต_ุงูุงุชูุงููุฉ"] = "โข " + p["ููุฎุต_ุงูุงุชูุงููุฉ"].strip()

        if p.get("ุงูููุงุฏ"):
            merged["ุงูููุงุฏ"].extend(p["ุงูููุงุฏ"])

        for k in ["ููุฑุฉ_ุงูููุงูุงุช","ุงูุดุฑูุท_ุงูุฎุงุตุฉ","ุงูุดุฑูุท_ุงูุนุงูุฉ"]:
            if p.get(k):
                if merged[k]:
                    merged[k] += "\n" + p[k].strip()
                else:
                    merged[k] = p[k].strip()

    return merged


def _model_fallbacks(selected: str) -> list:
    seen, out = set(), []
    def add(m):
        if m and m not in seen:
            seen.add(m); out.append(m)

    add(selected)
    # ุฅู ูุงู 2.5 ุฌุฑูุจ 1.5 ูู ููุณ ุงูุนุงุฆูุฉ
    if "2.5" in selected:
        add(selected.replace("2.5", "1.5"))

    # ูุฌููุนุฉ ููุณุนุฉ ูู ุงูุฃุณูุงุก ุงูุดุงุฆุนุฉ
    add("models/gemini-1.5-pro")
    add("models/gemini-1.5-flash")
    add("models/gemini-1.5-pro-001")
    add("models/gemini-1.5-flash-001")
    return out


# ===========================
# ุฃุฏูุงุช ุงูุชุฌุฒุฆุฉ ูุงูุฏูุฌ + ูุงุฆูุฉ ุงูููุฏููุงุช ุงูุงุญุชูุงุทูุฉ
# ===========================
def chunk_text(text: str, max_chars: int = 10000) -> list:
    """
    ููุต ุงููุต ููุทุน ุฃูุตุฑ ุญุชู ูุง ูุฑูุถู ุงูููุฏูู ุจุณุจุจ ุงูุทูู.
    ูุฑุงุนู ุงููุต ุนูุฏ ููุงูุฉ ุณุทุฑ ุฅู ุฃููู.
    """
    text = text or ""
    if len(text) <= max_chars:
        return [text]
    chunks, start = [], 0
    while start < len(text):
        end = min(len(text), start + max_chars)
        # ุญุงูู ุงููุต ุนูุฏ ุฃูุฑุจ ุณุทุฑุ ุจุดุฑุท ุฃูุง ูุฑุฌุน ูุซูุฑุงู
        nl = text.rfind("\n", start, end)
        if nl == -1 or nl <= start + int(max_chars * 0.5):
            nl = end
        chunk = text[start:nl].strip()
        if chunk:
            chunks.append(chunk)
        start = nl
    return chunks

def merge_results(parts: list) -> dict:
    """
    ูุฏูุฌ ูุชุงุฆุฌ ูุชุนุฏุฏุฉ ูู parse_tagged_response ูู ูุชูุฌุฉ ูุงุญุฏุฉ.
    ูุฃุฎุฐ ุฃูู ูููุฉ ุบูุฑ ูุงุฑุบุฉ ููุญููู ุงููุฑุฏูุฉ ููุฌูุน ุงูุฌุฏุงูู ูุงููุตูุต.
    """
    merged = {
        "ุงููุฑูู_ุงูุฃูู": None,
        "ุงููุฑูู_ุงูุซุงูู": None,
        "ุชุงุฑูุฎ_ุงูุจุฏุก": None,
        "ุชุงุฑูุฎ_ุงูุงูุชูุงุก": None,
        "ููุฎุต_ุงูุงุชูุงููุฉ": "",
        "ุงูููุงุฏ": [],
        "ููุฑุฉ_ุงูููุงูุงุช": "",
        "ุงูุดุฑูุท_ุงูุฎุงุตุฉ": "",
        "ุงูุดุฑูุท_ุงูุนุงูุฉ": ""
    }

    def first_nonempty(cur, new):
        return cur if (cur and str(cur).strip()) else (new if (new and str(new).strip()) else cur)

    for p in parts or []:
        merged["ุงููุฑูู_ุงูุฃูู"]    = first_nonempty(merged["ุงููุฑูู_ุงูุฃูู"],    p.get("ุงููุฑูู_ุงูุฃูู"))
        merged["ุงููุฑูู_ุงูุซุงูู"]   = first_nonempty(merged["ุงููุฑูู_ุงูุซุงูู"],   p.get("ุงููุฑูู_ุงูุซุงูู"))
        merged["ุชุงุฑูุฎ_ุงูุจุฏุก"]     = first_nonempty(merged["ุชุงุฑูุฎ_ุงูุจุฏุก"],     p.get("ุชุงุฑูุฎ_ุงูุจุฏุก"))
        merged["ุชุงุฑูุฎ_ุงูุงูุชูุงุก"]  = first_nonempty(merged["ุชุงุฑูุฎ_ุงูุงูุชูุงุก"],  p.get("ุชุงุฑูุฎ_ุงูุงูุชูุงุก"))

        if p.get("ููุฎุต_ุงูุงุชูุงููุฉ"):
            if merged["ููุฎุต_ุงูุงุชูุงููุฉ"]:
                merged["ููุฎุต_ุงูุงุชูุงููุฉ"] += "\nโข " + p["ููุฎุต_ุงูุงุชูุงููุฉ"].strip()
            else:
                merged["ููุฎุต_ุงูุงุชูุงููุฉ"] = "โข " + p["ููุฎุต_ุงูุงุชูุงููุฉ"].strip()

        if p.get("ุงูููุงุฏ"):
            merged["ุงูููุงุฏ"].extend([x for x in p["ุงูููุงุฏ"] if isinstance(x, dict)])

        for k in ["ููุฑุฉ_ุงูููุงูุงุช","ุงูุดุฑูุท_ุงูุฎุงุตุฉ","ุงูุดุฑูุท_ุงูุนุงูุฉ"]:
            if p.get(k):
                if merged[k]:
                    merged[k] += "\n" + p[k].strip()
                else:
                    merged[k] = p[k].strip()

    return merged

def _model_fallbacks(selected: str) -> list:
    """
    ูุจูู ูุงุฆูุฉ ููุฏููุงุช ูุฌุฑุจูุง ุจุงูุชุณูุณู.
    """
    seen, out = set(), []
    def add(m):
        if m and m not in seen:
            seen.add(m); out.append(m)

    add(selected)
    if "2.5" in selected:
        add(selected.replace("2.5", "1.5"))

    add("models/gemini-1.5-pro")
    add("models/gemini-1.5-flash")
    add("models/gemini-1.5-pro-001")
    add("models/gemini-1.5-flash-001")
    return out


# ===========================
# 5๏ธโฃ ุชุญููู ุจุงูู Gemini
# ===========================
def analyze_agreement_with_gemini(text: str, selected_model: str, debug: bool = False) -> dict:
    """
    ุฃููุงู ูุญุงูู ุชุญููู ูุงูู ุงููุต. ุฅุฐุง ูุดู (ุฑุฏ ูุงุถู/ูุฑููุถ/ุฎุทุฃ)ุ
    ููุชูู ููุฎุทุฉ (ุจ): ุชูุณูู ุงููุต ููุทุน ูุชุดุบูู ุงูุชุญููู ุนูู ูู ูุทุนุฉุ ุซู ุฏูุฌ ุงููุชูุฌุฉ.
    """
    prompt_full = AGREEMENT_PROMPT_TEMPLATE.format(doc_text=text)

    def run_once(model_name: str, prompt: str) -> str:
        model = genai.GenerativeModel(model_name=model_name)
        resp = model.generate_content(
            prompt,
            generation_config={"temperature": 0.15, "max_output_tokens": 8192}
        )
        raw = getattr(resp, "text", "") or ""
        if not raw and getattr(resp, "candidates", None):
            parts = [p.text for c in resp.candidates for p in getattr(c.content, "parts", []) if getattr(p, "text", "")]
            raw = "\n".join(parts)
        return raw

    # 1) ูุญุงููุฉ ูุงููุฉ ูุน fallback ุนูู ุงูููุฏููุงุช
    for m in _model_fallbacks(selected_model):
        try:
            raw = run_once(m, prompt_full)
            if debug:
                st.caption(f"๐ Raw (full) from {m}:")
                st.code((raw or "")[:1200] + ("..." if raw and len(raw) > 1200 else ""))
            parsed = parse_tagged_response(raw)
            # ูู ูู ุงูุญููู ูุงุฑุบุฉ ุชูุฑูุจุงูุ ุงุนุชุจุฑู ูุดู ููุทูู
            if any([parsed.get("ุงููุฑูู_ุงูุฃูู"), parsed.get("ุงููุฑูู_ุงูุซุงูู"), parsed.get("ุงูููุงุฏ")]):
                return parsed
        except Exception as e:
            if debug:
                st.warning(f"โ๏ธ ูุดู ูุญุงููุฉ ูุงููุฉ ุนูู {m}: {type(e).__name__}: {e}")

    # 2) ุฎุทุฉ (ุจ): ุชุฌุฒุฆุฉ ุงููุต
    chunks = chunk_text(text, max_chars=10000)
    parts = []
    for idx, ch in enumerate(chunks, 1):
        prompt_chunk = AGREEMENT_PROMPT_TEMPLATE.format(doc_text=ch)
        ok = False
        for m in _model_fallbacks(selected_model):
            try:
                raw = run_once(m, prompt_chunk)
                if debug:
                    st.caption(f"๐ Raw (chunk {idx}/{len(chunks)}) from {m}:")
                    st.code((raw or "")[:800] + ("..." if raw and len(raw) > 800 else ""))
                parsed = parse_tagged_response(raw)
                parts.append(parsed)
                ok = True
                break
            except Exception as e:
                if debug:
                    st.warning(f"โ๏ธ ูุดู chunk {idx} ุนูู {m}: {type(e).__name__}: {e}")
                continue
        if not ok and debug:
            st.error(f"โ ูู ููุฌุญ ูู chunk {idx}")

    if not parts:
        raise RuntimeError("ูุดู ุงูุชุญููู ุนุจุฑ ุฌููุน ุงูููุฏููุงุช (ูุงูู + ูุฌุฒุฃ).")

    # ุฏูุฌ ุงููุชุงุฆุฌ ุงูุฌุฒุฆูุฉ
    merged = merge_results(parts)
    return merged

# ===========================
# 6๏ธโฃ ูุงุฌูุฉ Streamlit
# ===========================
st.set_page_config(page_title="ุชุญููู ุงุชูุงููุงุช ุงููุคุณุณุฉ ุงูุงุณุชููุงููุฉ ุงูุนุณูุฑูุฉ", layout="wide")
st.title("๐ ูุธุงู ุชุญููู ุงุชูุงููุงุช ุงููุคุณุณุฉ ุงูุงุณุชููุงููุฉ ุงูุนุณูุฑูุฉ")
st.markdown("ุจุงุณุชุฎุฏุงู **Google Vision OCR + Gemini AI**")

uploaded = st.file_uploader("๐ค ุงุฑูุน ุตูุฑุฉ ุฃู ููู PDF", type=["png", "jpg", "jpeg", "pdf"])

if uploaded and st.button("๐ ุงุณุชุฎุฑุงุฌ ุงููุต"):
    try:
        with st.spinner("ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ุงููุต ุนุจุฑ Google Vision..."):
            text = extract_text_any(uploaded)
        st.session_state["ocr_text"] = text
        st.success("โ ุชู ุงุณุชุฎุฑุงุฌ ุงููุต!")
    except Exception as e:
        st.error(f"โ ูุดู ุงุณุชุฎุฑุงุฌ ุงููุต: {e}")

# ุนุฑุถ ุงููุต
st.text_area("๐ ุงููุต ุงููุณุชุฎุฑุฌ:", st.session_state.get("ocr_text", ""), height=300)

# ุฅุนุฏุงุฏ Gemini
if GEMINI_KEY:
    st.success("โ ููุชุงุญ Gemini ุตุงูุญ.")
    models_list = genai.list_models()
    models = [m.name for m in models_list if "generateContent" in m.supported_generation_methods]
    selected_model = st.selectbox("ุงุฎุชุฑ ุงูููุฏูู:", models, index=0)
else:
    st.error("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ููุชุงุญ Gemini")

debug = st.toggle("๐ง ุฅุธูุงุฑ ูุฎุฑุฌุงุช ุงูุชุดุฎูุต (Raw)")

if "ocr_text" in st.session_state and st.button("ุชุญููู ุงูุงุชูุงููุฉ"):
    try:
        result = analyze_agreement_with_gemini(st.session_state["ocr_text"], selected_model, debug)
        st.success("โ ุชู ุงูุชุญููู ุจูุฌุงุญ")
        st.json(result)
    except Exception as e:
        st.error(f"โ ูุดู ุงูุชุญููู: {e}")
